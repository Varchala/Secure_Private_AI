{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated_Learning_varchala.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9pL-G5SDcHzB",
        "OgbTAVRWQY4E",
        "hB-qzc_Shf-Q",
        "_hVQLH5uhcu5",
        "HTJ0I2kLm-Eq",
        "rMUHww-1q5Hg",
        "Tf1tTWbprGLD",
        "DEJ-y3YXu7pH",
        "UeaM8Uuo6u9D",
        "aCDcKszC6u9G",
        "wr8D6oJT6u9J",
        "M3C8S-3t6u9O",
        "c7KdhJ9V6u9R",
        "ilRqeeKO6u9X",
        "oUAo6rqz6u9a",
        "05kAABtz6u9e"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varchala/Secure_Private_AI/blob/main/Federated_Learning_varchala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjYCLnY600Y2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLqwL9nAp9pN",
        "outputId": "4229c70b-3ad8-4eeb-fd16-1082858d2dec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kjrh2K6tJUG"
      },
      "source": [
        "!pip install tensorflow_federated==0.13.1 --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMCDdVbN_2AU"
      },
      "source": [
        "!pip install -U git+https://github.com/tensorflow/privacy --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugj6pwbYmVjm"
      },
      "source": [
        "# !pip install --upgrade tensorflow --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URz6pyoYqYzL"
      },
      "source": [
        "# tensorflow_federated_nightly also bring in tf_nightly, which\n",
        "# can causes a duplicate tensorboard install, leading to errors.\n",
        "# !pip uninstall --yes tensorboard tb-nightly\n",
        "\n",
        "# !pip install --quiet --upgrade tensorflow-federated-nightly\n",
        "# !pip install --quiet --upgrade nest-asyncio\n",
        "# !pip install --quiet --upgrade tb-nightly  # or tensorboard, but not both\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksja49SUCxP"
      },
      "source": [
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-QME01r_Aa"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDdNChWdsS1o",
        "outputId": "50d02894-7303-4f19-9100-d08d3a1b4c78"
      },
      "source": [
        "import collections\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import InputLayer, Reshape\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "np.random.seed(0)\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset   \n",
        "torch.backends.cudnn.benchmark=True\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W_zVo50usM7"
      },
      "source": [
        "# Next version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oadc_DyBuyHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392b2dd8-8a1a-468b-dc2f-5ef31f2cb240"
      },
      "source": [
        "(x_train_100, y_train_100), (x_test_100, y_test_100) = cifar100.load_data()\n",
        "# y_test = to_categorical(y_test, 100)\n",
        "# y_train = to_categorical(y_train, 100)\n",
        "x_train_100 = x_train_100.astype('float32')\n",
        "x_test_100 = x_test_100.astype('float32')\n",
        "x_train_100  /= 255\n",
        "x_test_100 /= 255\n",
        "# print(y_train.shape)\n",
        "# assert x_train_100.shape == (50000, 32, 32, 3)\n",
        "# assert x_test.shape == (10000, 32, 32, 3)\n",
        "# assert y_train.shape == (50000, 100)\n",
        "# assert y_test.shape == (10000, 100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqapYIpHYKlX",
        "outputId": "4e4441a9-1daf-4253-d2b1-a8047f709e34"
      },
      "source": [
        "x_train_100.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojFjCWQUSai-",
        "outputId": "45b068d0-46e8-4593-a7d7-ae31492c385a"
      },
      "source": [
        "y_train_100.flatten()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 29,  0, ...,  3,  7, 73])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5N-btywxP1p"
      },
      "source": [
        "def extract_n_classes( data, labels,n, cat_y = True):\n",
        "    data_cl=[]\n",
        "    y=[]\n",
        "    # print(data.shape)\n",
        "    for i in range(n):\n",
        "            # print(data[ np.argwhere( labels == i ).reshape(-1) ].shape)\n",
        "            # print(labels.shape)\n",
        "            # print(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1)].shape,data.shape)\n",
        "            data_cl.append(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1) ][ : ])\n",
        "            y.extend(np.full((data_cl[i].shape[0]), i, dtype=int))\n",
        "\n",
        "    # print(np.array(data_cl).shape)\n",
        "    x = np.vstack( (data_cl) )\n",
        "    y = np.array(y)\n",
        "    # print(\"In extract classes function\")\n",
        "    # print(x.shape,y.shape)\n",
        "    return x, y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khpDewX-wlgw"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = extract_n_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHFHvX28iSnN"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjvWANxoiifx",
        "outputId": "2136c97d-0e84-4f64-d68e-5001c793c858"
      },
      "source": [
        "x_test.shape,y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 32, 32, 3), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtpRazzLin91"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dtCUKhEi3rf",
        "outputId": "19201874-1650-413c-b1f3-e4e3ebd7a941"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKYFpb6iiuFQ",
        "outputId": "63f7fb3d-5ad4-48ce-b347-ae30db0094b7"
      },
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              " array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "        100, 100, 100, 100, 100, 100, 100, 100, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvXzN3VZ87rH",
        "outputId": "22eac990-34d1-4e42-aa8f-e93556f2cdc4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw3DCZwy-lyI"
      },
      "source": [
        "# from collections import defaultdict\n",
        "# dataset={}\n",
        "# dataset['image'] = data.reshape(-1,3072)\n",
        "# dataset['label'] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGC4Inu_DzrL"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW0qjV81RqF4",
        "outputId": "dcaaaaa6-a5fb-4248-ba4f-86220f6ffd71"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqIGLe29QqoV",
        "outputId": "52b2ceba-7891-4f73-c6d8-62bcfe254c64"
      },
      "source": [
        "np.unique(y_train, return_counts=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              " array([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
              "        500, 500, 500, 500, 500, 500, 500, 500, 500]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pL-G5SDcHzB"
      },
      "source": [
        "## 1) Every party only holds instances of one class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgbTAVRWQY4E"
      },
      "source": [
        "### 1) 10 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bA-mt5XlPR",
        "outputId": "c3c84bd3-dfea-4a09-94d9-6f156da87092"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOoMfCPMcDO6",
        "outputId": "72bf3599-175a-4b27-f801-021900cccc00"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uTgzDNIdwA8",
        "outputId": "b2a9cea3-a270-4005-977b-5a5646c2f7cf"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eVxRHn2tzcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbc02ff-13bf-470c-d98d-43460f62733a"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.06882999837398529,loss=4.302463531494141,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.12751999497413635,loss=3.902362585067749,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.1748799979686737,loss=3.5745668411254883,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.21015000343322754,loss=3.371450424194336,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.24036000669002533,loss=3.214587450027466,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.2699599862098694,loss=3.0833005905151367,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.2941400110721588,loss=2.9663169384002686,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.3153899908065796,loss=2.861238479614258,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.3388800024986267,loss=2.7609798908233643,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.359470009803772,loss=2.669386148452759,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 10 <sparse_categorical_accuracy=0.3792800009250641,loss=2.584848403930664,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 11 <sparse_categorical_accuracy=0.3954299986362457,loss=2.5037410259246826,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 12 <sparse_categorical_accuracy=0.41356000304222107,loss=2.426600694656372,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 13 <sparse_categorical_accuracy=0.43121999502182007,loss=2.35532808303833,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 14 <sparse_categorical_accuracy=0.44745999574661255,loss=2.283499002456665,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 15 <sparse_categorical_accuracy=0.46546998620033264,loss=2.216397285461426,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 16 <sparse_categorical_accuracy=0.4797700047492981,loss=2.1485095024108887,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 17 <sparse_categorical_accuracy=0.49434998631477356,loss=2.0882227420806885,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 18 <sparse_categorical_accuracy=0.5092499852180481,loss=2.029247760772705,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 19 <sparse_categorical_accuracy=0.52360999584198,loss=1.967319369316101,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 201.67857098579407s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-qzc_Shf-Q"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO0MH6dOjHK8",
        "outputId": "1b7d2983-18ca-4103-ac99-a2a80793d13b"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oMyPLnQhb6y",
        "outputId": "4a2aec99-19e3-482e-f6fa-59148bce89ec"
      },
      "source": [
        "NO_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV425QoSkIGe",
        "outputId": "4b2524af-6432-47f4-af12-795cbcdd4a3c"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbQd37HkO97"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM4qhT3OmtS5",
        "outputId": "0cf4b0b8-707b-4665-d3e6-06d079fa6c1e"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.14399999380111694,loss=4.153222560882568,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hVQLH5uhcu5"
      },
      "source": [
        "### 2) 20 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rupwynTfpPFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir0Bvsv2pPXc"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = extract_n_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSn8xtVdpPXd"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xqlzpXApPXd"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9bU0WCpPXd"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nh_Zimohcu5",
        "outputId": "fb1fe52c-9e52-4715-db80-93815f580c3f"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSotkfIChcu5",
        "outputId": "ea45efe0-1477-4bee-8889-db2eaf49fdee"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB6xJs09hcu5",
        "outputId": "241d0e01-2c37-42a9-fb2f-64546d815cd3"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwzFFsCMhcu6",
        "outputId": "e338858f-8c44-4a7a-df9e-6d8b6eb2d72c"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9968000054359436,loss=0.02838919870555401,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9968699812889099,loss=0.021680328994989395,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9969499707221985,loss=0.01897040754556656,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.9969850182533264,loss=0.016871197149157524,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.996999979019165,loss=0.015239870175719261,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9969900250434875,loss=0.01391354575753212,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9970600008964539,loss=0.012825400568544865,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9970999956130981,loss=0.01204193476587534,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9970750212669373,loss=0.011504074558615685,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9971250295639038,loss=0.010982529260218143,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 10 <sparse_categorical_accuracy=0.9971349835395813,loss=0.010838828980922699,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 11 <sparse_categorical_accuracy=0.997189998626709,loss=0.010588651522994041,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 12 <sparse_categorical_accuracy=0.9972299933433533,loss=0.010380142368376255,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 13 <sparse_categorical_accuracy=0.9971799850463867,loss=0.010214089415967464,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 14 <sparse_categorical_accuracy=0.9972350001335144,loss=0.010196957737207413,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 15 <sparse_categorical_accuracy=0.9972550272941589,loss=0.01001393049955368,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 16 <sparse_categorical_accuracy=0.9972699880599976,loss=0.009910913184285164,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 17 <sparse_categorical_accuracy=0.9973750114440918,loss=0.009796414524316788,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 18 <sparse_categorical_accuracy=0.9971849918365479,loss=0.00977996177971363,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 19 <sparse_categorical_accuracy=0.9972550272941589,loss=0.00972004234790802,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 435.6161868572235s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIm-gu6m8Mb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTJ0I2kLm-Eq"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEdH2pJtm-Eq",
        "outputId": "30fb3d36-6057-4276-8aff-23c3c066afd4"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb1K9Iq-m-Eq",
        "outputId": "822d7c5f-7f91-4f8a-9577-9d651d5f0d46"
      },
      "source": [
        "NO_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab6294Jxm-Eq",
        "outputId": "6fa5db46-3a5b-4c41-c9b8-cc9946f643b6"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVpe2-y8m-Er"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvyPrbgOm-Er",
        "outputId": "9b814bab-971c-44f5-ca04-dec38485efc6"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.14149999618530273,loss=2.9097464084625244,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMUHww-1q5Hg"
      },
      "source": [
        "### 3) 50 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QEItYnXq_zN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA-FDb8PrGLC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQyiIpbxrGLC"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = extract_n_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqGO5mMrGLC"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1eH6QIArGLC"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "760986YLrGLC"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9JJS0g4rGLC",
        "outputId": "a485b1f3-922b-48c2-a0b8-cc13e34989d3"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64502L6arGLD",
        "outputId": "e26becad-b4ee-46d5-af3e-cfaa623a131d"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO_dtYNqrGLD",
        "outputId": "73764fda-d992-4fbf-f6b6-b4c00a485477"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTlj0B6OrGLD",
        "outputId": "755d60ed-c1a0-4fa3-a9b9-368e43f63e5e"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9967820048332214,loss=0.029505418613553047,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9968259930610657,loss=0.025112411007285118,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9968720078468323,loss=0.023170992732048035,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.996891975402832,loss=0.021677041426301003,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.9969019889831543,loss=0.02052840031683445,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9968960285186768,loss=0.01954890787601471,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9969000220298767,loss=0.01855125091969967,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9969019889831543,loss=0.017708012834191322,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9968979954719543,loss=0.01692487858235836,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9969019889831543,loss=0.01640350930392742,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 10 <sparse_categorical_accuracy=0.9969140291213989,loss=0.015806647017598152,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 11 <sparse_categorical_accuracy=0.996940016746521,loss=0.01537012867629528,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 12 <sparse_categorical_accuracy=0.9969140291213989,loss=0.015007366426289082,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 13 <sparse_categorical_accuracy=0.996936023235321,loss=0.014634357765316963,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 14 <sparse_categorical_accuracy=0.9969300031661987,loss=0.014354575425386429,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 15 <sparse_categorical_accuracy=0.9969180226325989,loss=0.014059226959943771,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 16 <sparse_categorical_accuracy=0.9969220161437988,loss=0.013912225142121315,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 17 <sparse_categorical_accuracy=0.9969320297241211,loss=0.013728782534599304,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 18 <sparse_categorical_accuracy=0.9969279766082764,loss=0.013634737581014633,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 19 <sparse_categorical_accuracy=0.9969260096549988,loss=0.013529776595532894,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 1082.8748824596405s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBlktaMmrGLD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf1tTWbprGLD"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPHn2fnArGLD",
        "outputId": "e59f606b-d411-43e7-a209-9984c790da96"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWS_KRZKrGLD",
        "outputId": "f5b67a48-8ec6-45d1-f11d-ce491ed3603b"
      },
      "source": [
        "NO_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cri8T1BurGLD",
        "outputId": "5c1537d1-b2a5-4354-f87b-c5e5f39c45f1"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS-EoQcUrGLD"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYgrBdH6rGLE",
        "outputId": "1624190a-e472-4012-b082-30a5f69f5792"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.04259999841451645,loss=3.9147067070007324,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6YI6FgHu68z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJ-y3YXu7pH"
      },
      "source": [
        "### 3) 100 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiuxkrkku7pH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9leLxNNu7pH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA7fcwkBu7pH"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = extract_n_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtpZfkyTu7pH"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9_tnVQKu7pH"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ttrI7Fu7pH"
      },
      "source": [
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rj36U5u7pH",
        "outputId": "f450006b-2177-4810-df00-a93e2d5db40d"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nYiuYzsu7pH",
        "outputId": "8e8edca5-59fb-4957-a5c1-20cba4182c92"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mtfcZPgu7pI",
        "outputId": "f60ffcca-e332-414f-b90f-33a52c1018c6"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kk5HIjKu7pI",
        "outputId": "838fdbab-f521-4cba-b51b-ef8e52ba1644"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f3e703980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.9968159794807434,loss=0.031106669455766678,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.9968420267105103,loss=0.02494497410953045,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.9968379735946655,loss=0.023496944457292557,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.9968410134315491,loss=0.02237214520573616,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.996849000453949,loss=0.021402334794402122,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.9968439936637878,loss=0.02064037136733532,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.9968299865722656,loss=0.019981471821665764,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.9968360066413879,loss=0.01941506192088127,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.9968339800834656,loss=0.018966615200042725,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.9968339800834656,loss=0.018528606742620468,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 10 <sparse_categorical_accuracy=0.9968379735946655,loss=0.018188219517469406,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 11 <sparse_categorical_accuracy=0.9968349933624268,loss=0.017838699743151665,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 12 <sparse_categorical_accuracy=0.9968299865722656,loss=0.017582857981324196,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 13 <sparse_categorical_accuracy=0.9968339800834656,loss=0.0173275638371706,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 14 <sparse_categorical_accuracy=0.996845006942749,loss=0.017064938321709633,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 15 <sparse_categorical_accuracy=0.9968510270118713,loss=0.016831401735544205,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 16 <sparse_categorical_accuracy=0.9968379735946655,loss=0.016713298857212067,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 17 <sparse_categorical_accuracy=0.9968420267105103,loss=0.016541466116905212,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 18 <sparse_categorical_accuracy=0.9968400001525879,loss=0.016326261684298515,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 19 <sparse_categorical_accuracy=0.996849000453949,loss=0.016225920990109444,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 2246.4805884361267s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1MHRQx5u7pI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HVaPn0_u7pI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2bKVyA9u7pI",
        "outputId": "a58b1a15-618f-4090-b9c2-26af7100c021"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXbAI3ZkW9XK",
        "outputId": "4f34571d-a1d0-40b0-b7f6-0f5993dacdb7"
      },
      "source": [
        "y_test[0:100]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDTsGl-0u7pI",
        "outputId": "3f9507da-4992-4bf8-b956-bb2502e41ea4"
      },
      "source": [
        "NO_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // 100 # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(100,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhz1r96Su7pI",
        "outputId": "e6c6fe0d-ab7e-404f-ab33-03674b3a866c"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrYtGQLeu7pI"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdcNE9ciu7pJ",
        "outputId": "26f86b9a-198a-4f62-89bb-ed267fcac7b8"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.014700000174343586,loss=4.6707353591918945,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrXvu7Cx5j_7"
      },
      "source": [
        "state, metrics = algorithm.next( state, data )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sodzwNyI6TaF"
      },
      "source": [
        "# algorithm."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FBUXiI5m7W",
        "outputId": "2e528ad0-c942-40c8-a605-167ec01053ff"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnonymousTuple([('sparse_categorical_accuracy', 0.9904), ('loss', 0.04821914), ('keras_training_time_client_sum_sec', 0.0)])"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XnZs4v50CC"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r2HAGXd52_e",
        "outputId": "0f61c630-f73e-4042-8f90-a79bf2881551"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.0142000000923872,loss=4.6595377922058105,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ywnAo1U6upv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veWUt8aO6u9C"
      },
      "source": [
        "## 1) Every party has instances of every class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u7piAo9NcWH"
      },
      "source": [
        "def extract_n_classes( data, labels,n, cat_y = True):\n",
        "    data_cl=[]\n",
        "    y=[]\n",
        "    # print(data.shape)\n",
        "    for i in range(n):\n",
        "            # print(data[ np.argwhere( labels == i ).reshape(-1) ].shape)\n",
        "            # print(labels.shape)\n",
        "            # print(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1)].shape,data.shape)\n",
        "            data_cl.append(data[ np.argwhere( labels.reshape(-1) == i ).reshape(-1) ][ : ])\n",
        "            y.extend(np.full((data_cl[i].shape[0]), i, dtype=int))\n",
        "\n",
        "    # print(np.array(data_cl).shape)\n",
        "    x = np.vstack( (data_cl) )\n",
        "    y = np.array(y)\n",
        "    # print(\"In extract classes function\")\n",
        "    # print(x.shape,y.shape)\n",
        "    return x, y"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI36lI8SO_bt"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train, y_train = extract_n_classes( x_train_100, y_train_100 ,n=100,cat_y=False)\n",
        "session = tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EwhF66BgL_f"
      },
      "source": [
        "x_test = x_test.reshape(-1,3072)\n",
        "x_train = x_train.reshape(-1,3072)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-1ZxdjEbCCR",
        "outputId": "feb1eae4-3e9c-4c4f-9fce-3ff0c4681620"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHmXr7gLJLwo"
      },
      "source": [
        "### Following function arranges data such that the examples corresponsing to the labels come is 0,1,2,3,4,.....99,0,1,2,3,......99.......99\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS3LZBBPP7cu"
      },
      "source": [
        "\n",
        "x_new = []\n",
        "y_new = []\n",
        "for i in range(500):\n",
        "    for j in range(x_train.shape[0]//500):\n",
        "        x_new.append(x_train[j*500+i])\n",
        "        y_new.append(y_train[j*500+i])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ndqWGJbaVqm",
        "outputId": "cfb5e552-ae17-4916-e47a-3db3bb6719c3"
      },
      "source": [
        "x_new = np.array(x_new)\n",
        "x_new.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm8R_k_ofHsG",
        "outputId": "4d725765-343c-4d30-e35c-cdc219227973"
      },
      "source": [
        "y_new = np.array(y_new)\n",
        "y_new.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXDNqLRne7Bc",
        "outputId": "b1d0caf6-34f0-41bd-ea70-6e185b9791f6"
      },
      "source": [
        "print(y_new[0:100])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaM8Uuo6u9D"
      },
      "source": [
        "### 1) 10 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPByHKDk6u9D",
        "outputId": "acfa134d-9fe8-46e9-9468-a657b6e8b290"
      },
      "source": [
        "x_new.shape[ 0 ]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i46sdNmJ6u9E",
        "outputId": "e2f2c9de-1f14-4acf-aa35-9e1f9d72c87f"
      },
      "source": [
        "y_new[501]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CJhAjc76u9F",
        "outputId": "3c0d2d11-e045-465f-e666-92e24e5a881a"
      },
      "source": [
        "x_new.shape[ 0 ]//100"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEuN1ZnZf5Vy"
      },
      "source": [
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeTXLXa86u9F",
        "outputId": "28120742-2d6c-4946-e2ba-8e3f4a1f59cc"
      },
      "source": [
        "%%time\n",
        "# parameters\n",
        "NO_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(5000, 3072)\n",
            "(5000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "epoch 0 <sparse_categorical_accuracy=0.05217599868774414,loss=4.300050735473633,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.11260200291872025,loss=3.8745040893554688,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.14607200026512146,loss=3.68692946434021,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.16494399309158325,loss=3.577561855316162,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.18025599420070648,loss=3.4952189922332764,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.19226199388504028,loss=3.4264943599700928,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.20326200127601624,loss=3.36643385887146,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.21314600110054016,loss=3.3139567375183105,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.22159400582313538,loss=3.2666213512420654,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.22960199415683746,loss=3.2231192588806152,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 349.08038663864136s\n",
            "CPU times: user 10min 21s, sys: 32.5 s, total: 10min 54s\n",
            "Wall time: 5min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCDcKszC6u9G"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A838Kx3ui8Sg",
        "outputId": "d4e29336-d37a-4887-d10d-a51cd437dbfb"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl_gX_Zv6u9H",
        "outputId": "0870f4c7-6efe-479b-916b-f2db0b7abdf8"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bRj9l0z6u9H",
        "outputId": "fe6b9553-97eb-4e76-d0dd-65aa50f4f5cd"
      },
      "source": [
        "NO_CLIENTS = 10 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(NO_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 1, 3072)\n",
            "(1000, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoBH3W1w6u9I"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwMOPsi6u9I"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shOZzAp_6u9J",
        "outputId": "b7649221-e69f-4ba9-fd3b-eec01e43a76b"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.20250000059604645,loss=3.4426770210266113,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr8D6oJT6u9J"
      },
      "source": [
        "### 2) 20 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbzlhxc6u9K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_BNSjTP6u9K"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avUiBIA86u9K"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aADzV0S46u9M",
        "outputId": "088568b9-0166-457c-e8da-db35f1023f4a"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa19SKVy6u9M",
        "outputId": "45f6ae6a-6095-4f12-b530-1f6f4152c6c2"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoMi1k1x6u9M",
        "outputId": "1ca2e134-eab5-4e4a-e531-e894bb579b46"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1e6dWKc6u9N",
        "outputId": "5770bc02-30ec-4b4b-8143-7eb5bc566200"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(2500, 3072)\n",
            "(2500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.03213400021195412,loss=4.477772235870361,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.07795400172472,loss=4.09898042678833,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.11436200141906738,loss=3.8583664894104004,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.13838399946689606,loss=3.7215287685394287,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.15478600561618805,loss=3.6306722164154053,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.1678059995174408,loss=3.562695026397705,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.17857399582862854,loss=3.5056324005126953,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.18853400647640228,loss=3.455397605895996,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.1966799944639206,loss=3.4092166423797607,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.2049179971218109,loss=3.3677499294281006,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 775.7347240447998s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XEvmepD6u9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3C8S-3t6u9O"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FFJCuhB6u9P",
        "outputId": "d31c562a-8401-4505-9533-7b765c6c7923"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5b2PAqH6u9P",
        "outputId": "5b9db56a-8623-4b8e-c270-adc9a2b6cfc5"
      },
      "source": [
        "NO_CLIENTS = 20 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(NO_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 1, 3072)\n",
            "(500, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvaxHS-_6u9Q",
        "outputId": "a68a75e6-f7a3-4190-cb7d-756369be0b75"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_esaP0H6u9Q"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-EWbOZ36u9Q",
        "outputId": "24146774-e6b4-49e4-e4d4-286aa89447e3"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.18209999799728394,loss=3.551243305206299,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KdhJ9V6u9R"
      },
      "source": [
        "### 3) 50 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1lQR-8M6u9R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcTuWnKZ6u9S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4WSFdpN6u9S"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RASacLdd6u9S"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tx2BlxR6u9U",
        "outputId": "38e1355e-fb21-488c-c64b-1c759944ac24"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJwrTjqK6u9U",
        "outputId": "e4a516e1-d541-4527-9e20-59b752335d7f"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvTpX9ZU6u9V",
        "outputId": "c3a31d70-af06-42b4-ef49-82f76d6d1cee"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jQi1q2ST6u9W",
        "outputId": "ea8bfa0d-7481-43e1-8a33-300902c5ba54"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(1000, 3072)\n",
            "(1000, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.04899799823760986,loss=4.396090030670166,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.11541800200939178,loss=3.9218549728393555,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.1563519984483719,loss=3.646138906478882,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.1839890033006668,loss=3.4922215938568115,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.2050500065088272,loss=3.3796703815460205,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.22156600654125214,loss=3.2927358150482178,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.23540900647640228,loss=3.2207276821136475,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.24752900004386902,loss=3.160170316696167,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.25799599289894104,loss=3.106736898422241,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.2669290006160736,loss=3.058450222015381,keras_training_time_client_sum_sec=0.0>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-1136335e2cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'epoch'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retrying.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mRetrying\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retrying.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_reject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mdelay_since_first_attempt_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retrying.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, wrap_exception)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retrying.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mattempt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/executors/execution_context.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    201\u001b[0m         return event_loop.run_until_complete(\n\u001b[1;32m    202\u001b[0m             tracing.run_coroutine_in_ambient_trace_context(\n\u001b[0;32m--> 203\u001b[0;31m                 _invoke(executor, comp, arg)))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_when\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86400\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             else None)\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mevent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1yV0-ic6u9W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilRqeeKO6u9X"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGXp2Oq26u9X",
        "outputId": "e59f606b-d411-43e7-a209-9984c790da96"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL9o46fE6u9Y",
        "outputId": "7e364de9-ff58-4ac3-8da0-b465d1f11e84"
      },
      "source": [
        "NO_CLIENTS = 50 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(NO_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(200, 1, 3072)\n",
            "(200, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uPIh5lZ6u9Y",
        "outputId": "c10a3d40-fca8-4f51-82eb-1d9063bb612a"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zErBKnzz6u9Z"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlpeuOTT6u9Z",
        "outputId": "e72dc081-e369-485e-d12c-8fcb4994225b"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.1793999969959259,loss=3.5994575023651123,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Qn0LQo6u9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUAo6rqz6u9a"
      },
      "source": [
        "### 4) 100 Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7EDm4A_6u9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmoMLZnn6u9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK4xsLHN6u9b"
      },
      "source": [
        "#extract equal ratio of all the classes for train\n",
        "x_train = x_new.copy()\n",
        "y_train = y_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtOILS9R6u9b"
      },
      "source": [
        "#extract equal ratio of all the classes for test\n",
        "x_test, y_test = extract_n_classes( x_test_100, y_test_100 ,n=100,cat_y=False)\n",
        "session =  tf.compat.v1.Session()\n",
        "tf.compat.v1.keras.backend.set_session( session )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWg78WHS6u9c",
        "outputId": "173cbb8d-3f58-4ebd-fc99-708c7f2525cc"
      },
      "source": [
        "x_train.shape[ 0 ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI1GQFQp6u9c",
        "outputId": "37c3871d-d38c-4e64-a466-b0478de97507"
      },
      "source": [
        "y_train[499]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCa-y3d6u9c",
        "outputId": "afe14826-03fd-47f2-f3ad-aef8c45131aa"
      },
      "source": [
        "x_train.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-irc8j2l6u9d",
        "outputId": "f37dc1d2-646e-4b52-f614-1df38e59c52c"
      },
      "source": [
        "\n",
        "# parameters\n",
        "NO_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_train.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# shuffle data\n",
        "# idx = np.arange( TOTAL_SAMPLES )\n",
        "# np.random.shuffle( idx )\n",
        "# x_train = x_train[ idx ]\n",
        "# y_train = y_train[ idx ]\n",
        "\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ]\n",
        "  print( x.shape )\n",
        "  y = y_train[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( [-1,1] ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "  ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )\n",
        "\n",
        "\n",
        "# define a function that builds our model\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add( tf.keras.layers.Dense( 64, activation='relu', input_shape=( x_train.shape[ 1: ] ) ) )\n",
        "  model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_function():\n",
        "  # we need a dummy batch to build the federated model\n",
        "  # From the docs:\n",
        "  # A nested structure of values that are convertible to batched tensors\n",
        "  # with the same shapes and types as expected by forward_pass(). \n",
        "  # The values of the tensors are not important and can be filled with any \n",
        "  # reasonable input value.\n",
        "  dummy_batch = collections.OrderedDict( [ \n",
        "      ('x', np.ones( ( BATCH_SIZE, x_train.shape[ 1 ] ) ) ),\n",
        "      ('y', np.ones( ( BATCH_SIZE, 1) ) ) ] )\n",
        "\n",
        "  # get the compiled keras model\n",
        "  model = build_model()\n",
        "  # use tensorflow function to create a federated learning model\n",
        "  return tff.learning.from_keras_model( model, loss=tf.keras.losses.SparseCategoricalCrossentropy(),  dummy_batch=dummy_batch, metrics=[tf.keras.metrics.SparseCategoricalAccuracy() ] )\n",
        "\n",
        "\n",
        "# use tensorflow to create the averaging algorithm\n",
        "algorithm = tff.learning.build_federated_averaging_process( model_function, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02 ) ) \n",
        "\n",
        "# initialize the learning algorithm and get the initial state\n",
        "state = algorithm.initialize()\n",
        "\n",
        "# run the training steps\n",
        "start = time.time()\n",
        "for e in range( EPOCHS ):\n",
        "    state, metrics = algorithm.next( state, data )\n",
        "    print( 'epoch' , e , metrics )\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "(500, 3072)\n",
            "(500, 1)\n",
            "<BatchDataset shapes: ((None, 3072), (None, 1)), types: (tf.float64, tf.float64)>\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x7f202c7bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "ERROR:asyncio:Task was destroyed but it is pending!\n",
            "task: <Task pending coro=<trace.<locals>.async_trace() running at /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/common_libs/tracing.py:281> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.7/asyncio/futures.py:351, Task.__wakeup()]> cb=[Task.__wakeup()]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 <sparse_categorical_accuracy=0.0243539996445179,loss=4.5499677658081055,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 1 <sparse_categorical_accuracy=0.03557400032877922,loss=4.488467216491699,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 2 <sparse_categorical_accuracy=0.04927999898791313,loss=4.385908603668213,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 3 <sparse_categorical_accuracy=0.06531199812889099,loss=4.244858264923096,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 4 <sparse_categorical_accuracy=0.08216000348329544,loss=4.096020221710205,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 5 <sparse_categorical_accuracy=0.09690000116825104,loss=3.9840710163116455,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 6 <sparse_categorical_accuracy=0.10847199708223343,loss=3.901385545730591,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 7 <sparse_categorical_accuracy=0.1179099977016449,loss=3.838557243347168,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 8 <sparse_categorical_accuracy=0.12638600170612335,loss=3.7877678871154785,keras_training_time_client_sum_sec=0.0>\n",
            "epoch 9 <sparse_categorical_accuracy=0.1349020004272461,loss=3.743330478668213,keras_training_time_client_sum_sec=0.0>\n",
            "Training time: 1062.379156112671s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRKs9AR56u9d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05kAABtz6u9e"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALwwaqf56u9e",
        "outputId": "c8bb36bb-f562-49ff-9e9c-3e3604598c81"
      },
      "source": [
        "x_test.shape[ 0 ]//100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNTaNxUr6u9e",
        "outputId": "7a71ee6d-6d70-4701-cd48-0eb928475e33"
      },
      "source": [
        "NO_CLIENTS = 100 # number of clients\n",
        "TOTAL_SAMPLES = x_test.shape[ 0 ]\n",
        "NO_CLIENT_SAMPLES = TOTAL_SAMPLES // NO_CLIENTS # number of samples per client\n",
        "data = []\n",
        "# split into clients\n",
        "for i in range( NO_CLIENTS ):\n",
        "  x = x_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES  ].reshape(NO_CLIENT_SAMPLES,1,3072)\n",
        "  print( x.shape )\n",
        "  y = y_test[ i * NO_CLIENT_SAMPLES : ( i + 1 ) * NO_CLIENT_SAMPLES ].reshape( -1,1,1 ) \n",
        "  print( y.shape )\n",
        "  ds = tf.data.Dataset.from_tensor_slices( (x.astype( np.float ) , y.astype( np.float ) ) )\n",
        "#   ds = ds.repeat( EPOCHS ).shuffle( 200 ).batch( BATCH_SIZE )\n",
        "\n",
        "  print( ds )\n",
        "  data.append( ds )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n",
            "(100, 1, 3072)\n",
            "(100, 1, 1)\n",
            "<TensorSliceDataset shapes: ((1, 3072), (1, 1)), types: (tf.float64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn3P3wQP6u9e",
        "outputId": "97bbfc57-2639-44b8-8624-faa58631fc2b"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cVIiXd6u9f"
      },
      "source": [
        "test_metrics = evaluation(state.model, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5hwji_F6u9f",
        "outputId": "9675175a-38fa-42b1-8cab-89f4de0f996f"
      },
      "source": [
        "print(str(test_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sparse_categorical_accuracy=0.12060000002384186,loss=3.891695261001587,keras_training_time_client_sum_sec=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGr8IZXtPOzK"
      },
      "source": [
        "# Privacy Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blllyo5B2zQl"
      },
      "source": [
        "## I am using the 10 clients model from every party has instances of every class model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VEL44C4dfefI",
        "outputId": "ae8c626d-8022-49ba-beec-5c67606e2fc6"
      },
      "source": [
        "tff.__version__"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.13.1'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy76Fny02wF8",
        "outputId": "4af99577-e420-4133-9e50-67f9f7c95afe"
      },
      "source": [
        "# state.model.non_trainable.summary()\n",
        "state.model.trainable[3]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.23248132, -0.0125431 , -0.14318414,  0.250688  ,  0.38469976,\n",
              "       -0.23434952, -0.1126335 ,  0.01317185,  0.0620439 , -0.17180759,\n",
              "       -0.19698215, -0.11864652, -0.01803164,  0.08926512,  0.18667966,\n",
              "       -0.04394913, -0.19491448, -0.14071274,  0.05890048,  0.15100561,\n",
              "       -0.4371449 ,  0.4994448 , -0.25189635, -0.17176385, -0.31817666,\n",
              "       -0.11166035,  0.10329451,  0.26682028, -0.11757993, -0.02721741,\n",
              "        0.24795066,  0.27294898, -0.03678288,  0.4233782 ,  0.01397543,\n",
              "       -0.10276289, -0.35437813, -0.05042579,  0.0434991 , -0.08308277,\n",
              "       -0.20776892, -0.31029722,  0.3212758 ,  0.0909095 ,  0.0762846 ,\n",
              "        0.17890659,  0.11688788,  0.01461449,  0.13094157, -0.12350072,\n",
              "        0.00438271,  0.15840597, -0.02025284, -0.36373484, -0.18338042,\n",
              "        0.26968583,  0.04767029, -0.3036686 ,  0.02351335,  0.05479702,\n",
              "       -0.27954268, -0.41466045, -0.1750093 ,  0.24549101,  0.2274905 ,\n",
              "        0.01920389,  0.3251614 , -0.04381545, -0.16401173, -0.20486587,\n",
              "       -0.172126  , -0.1790776 ,  0.10627297,  0.10205817,  0.33524653,\n",
              "        0.1992689 , -0.03163071,  0.09603016,  0.23602416,  0.08853129,\n",
              "        0.13147287,  0.22473934, -0.06510326, -0.07757229, -0.18863513,\n",
              "       -0.04562481, -0.2508091 ,  0.03907547,  0.15911733,  0.1083342 ,\n",
              "        0.12753281, -0.12511349, -0.08645478,  0.07913606, -0.03182374,\n",
              "       -0.0550301 ,  0.12523364,  0.18607803, -0.07179359,  0.14086983],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpn7ZBmBZd2G",
        "outputId": "ee1df324-653c-42b1-9305-8727c7d947af"
      },
      "source": [
        "# tensorflow-privacy \n",
        "from tensorflow_privacy.privacy.membership_inference_attack import membership_inference_attack as mia\n",
        "from tensorflow_privacy.privacy.membership_inference_attack.data_structures import AttackInputData\n",
        "from tensorflow_privacy.privacy.membership_inference_attack.data_structures import SlicingSpec\n",
        "from tensorflow_privacy.privacy.membership_inference_attack.data_structures import AttackType"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_privacy/privacy/membership_inference_attack/__init__.py:19: UserWarning: \n",
            "Membership inference attack sources were moved. Please replace\n",
            "import tensorflow_privacy.privacy.membership_inference_attack\n",
            "\n",
            "with\n",
            "import tensorflow_privacy.privacy.privacy_tests.membership_inference_attack\n",
            "  \"\\nMembership inference attack sources were moved. Please replace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejcc0hbocutG"
      },
      "source": [
        "# since we have not specified an activation function on the last layer\n",
        "# calling the predict function returns the logits\n",
        "print('Predict on train...')\n",
        "logits_train = model.predict(train_data)\n",
        "print('Predict on test...')\n",
        "logits_test = model.predict(test_data)\n",
        "\n",
        "print('Apply softmax to get probabilities from logits...')\n",
        "prob_train = special.softmax(logits_train, axis=1)\n",
        "prob_test = special.softmax(logits_test, axis=1)\n",
        "\n",
        "print('Compute losses...')\n",
        "cce = tf.keras.backend.categorical_crossentropy\n",
        "constant = tf.keras.backend.constant\n",
        "\n",
        "y_train_onehot = to_categorical(train_labels)\n",
        "y_test_onehot = to_categorical(test_labels)\n",
        "\n",
        "loss_train = cce(constant(y_train_onehot), constant(prob_train), from_logits=False).numpy()\n",
        "loss_test = cce(constant(y_test_onehot), constant(prob_test), from_logits=False).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5bS_7qS2vCn"
      },
      "source": [
        "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack import membership_inference_attack as mia\n",
        "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackInputData\n",
        "\n",
        "# Suppose we have the labels as integers starting from 0\n",
        "# labels_train  shape: (n_train, )\n",
        "# labels_test  shape: (n_test, )\n",
        "\n",
        "# Evaluate your model on training and test examples to get\n",
        "# loss_train  shape: (n_train, )\n",
        "# loss_test  shape: (n_test, )\n",
        "\n",
        "# define what variables our attacker should have access to\n",
        "logits = state.model.trainable[3]\n",
        "attack_input = AttackInputData(\n",
        "  labels_train = y_train,\n",
        "  labels_test = y_test\n",
        ")\n",
        "# how should the data be sliced\n",
        "slicing_spec = SlicingSpec(\n",
        "    entire_dataset = True,\n",
        "    by_class = True,\n",
        "    by_percentiles = False,\n",
        "    by_classification_correctness = False)\n",
        "# define the type of attacker model that we want to use\n",
        "attack_types = [\n",
        "    AttackType.THRESHOLD_ATTACK\n",
        "]\n",
        "# print(attack_types)\n",
        "attacks_result = mia.run_attacks(attack_input=attack_input,\n",
        "                                 slicing_spec=slicing_spec,\n",
        "                                 attack_types=attack_types)\n",
        "\n",
        "print(attacks_result.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY-UAyUiBczl"
      },
      "source": [
        "\n",
        "# num = input (\"Enter number :\") \n",
        "# print(num) \n",
        "# name1 = input(\"Enter name : \") \n",
        "# print(name1) \n",
        "\n",
        "# # Printing type of input value \n",
        "# print (\"type of number\", type(num)) \n",
        "# print (\"type of name\", type(name1)) "
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}