{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "attack_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varchala/Secure_Private_AI/blob/main/attack_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1IIenRzV7Gv"
      },
      "source": [
        "# Attacking a CNN\n",
        "\n",
        "The CNN is vulnerable to adversarial examples as ![adv example](https://www.tensorflow.org/tutorials/generative/images/adversarial_example.png)\n",
        "\n",
        "In this exercise we will train a CNN to distinguish between instances of handwritten `0` and instances of handwritten `1`. We will be using `PyTorch` to do this.  \n",
        "\n",
        "Once we have a trained classifier, we will create adversarial examples from scratch using `ART`\n",
        "\n",
        "This is adopted from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:10.840140Z",
          "start_time": "2021-09-20T18:59:10.789703Z"
        },
        "id": "kmMmtRTmXzew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36e6860-a143-484e-94ae-7c435b3534ba"
      },
      "source": [
        "# some configurations for jupyter notebook\n",
        "%config Completer.use_jedi = False\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:12.977893Z",
          "start_time": "2021-09-20T18:59:11.491488Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhoEjgYmWJ0E",
        "scrolled": true,
        "outputId": "5f6f4bce-f6fb-4e74-8d33-740e005a7840"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.7.2 llvmlite-0.36.0 numba-0.53.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:13.946374Z",
          "start_time": "2021-09-20T18:59:12.981641Z"
        },
        "id": "iIH4d-w4V7G7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIL2ziyzV7G_"
      },
      "source": [
        "The MNIST dataset contains data for all digits.\n",
        "\n",
        "We need to normalize the data. Here, we use the API from `ART`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3nYU03lV7HD"
      },
      "source": [
        "Load the actual data. It will load the data as numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:17.725807Z",
          "start_time": "2021-09-20T18:59:16.771840Z"
        },
        "id": "CMKzVNfRV7HA"
      },
      "source": [
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:19.612010Z",
          "start_time": "2021-09-20T18:59:18.723730Z"
        },
        "id": "wHnEBGaaXze1"
      },
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 1a: Swap axes to PyTorch's NCHW format\n",
        "\n",
        "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:21.226435Z",
          "start_time": "2021-09-20T18:59:21.191616Z"
        },
        "id": "1s15HmICXze2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe0e810-31b6-4ff3-8686-017c26c9b0f2"
      },
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape, x_test.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(60000, 1, 28, 28) (10000, 1, 28, 28) (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64xNkKdV7HX"
      },
      "source": [
        "We are using a very simple CNN. This network can be used to distinguish between all 10 classes with very high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:27.699281Z",
          "start_time": "2021-09-20T18:59:27.651774Z"
        },
        "id": "GMjW64ADV7HY"
      },
      "source": [
        "# define the classifier\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 10)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkMTZ40wXze4"
      },
      "source": [
        "Then, we initialize a model and train with the cross-entropy loss.\n",
        "\n",
        "To simplify the training code, we use the wrapper `PyTorchClassifier` from `ART` to train the model. See https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:24.768984Z",
          "start_time": "2021-09-20T19:00:13.492134Z"
        },
        "id": "AVCIrvtnXze5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483d7090-be33-44d0-e401-a24ac59c61e7"
      },
      "source": [
        "# Step 2: Create the model\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# Step 2a: Define the loss function and the optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# the final accuracy should > 95%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 97.92999999999999%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:24.799098Z",
          "start_time": "2021-09-20T19:00:24.771574Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6Opy3LrxXze6"
      },
      "source": [
        "# the device(cpu/gpu) of the model\n",
        "\n",
        "device = next(model.parameters()).device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGVKqpNY0Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f13647-f591-48d4-f617-f8540eaebe3d"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0dNIotIQ_n"
      },
      "source": [
        "Let's get to the actual attack. First, we pick a sample that we want to perturb. After that we will be implementing our own FGSM attack. \n",
        "\n",
        "The attack is fairly simple. It consists of the following steps: \n",
        "\n",
        "1.   Compute the loss of the original sample\n",
        "2.   Calculate the gradient of the loss w.r.t the input \n",
        "3.   Take the sign of the gradient and add a fraction episilon to the input, namely $x + \\epsilon sign(\\nabla_x J(x, y))$\n",
        "\n",
        "Epsilon controlls the strenght of the pertubation.\n",
        "\n",
        "First, we select a sample to visualize it and output the model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:25.184151Z",
          "start_time": "2021-09-20T19:00:24.800964Z"
        },
        "id": "JOpIawNBXze7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "d4a80973-9dae-4f5a-fc2a-7308be661961"
      },
      "source": [
        "\n",
        "#chose a sample to pertubate\n",
        "sample_ind = 25 # chosen by totaly random dice roll\n",
        "\n",
        "# picking a test sample\n",
        "sample = x_test[ sample_ind, : ]\n",
        "\n",
        "print( sample.shape )\n",
        "\n",
        "# plot the first instance in the traning set\n",
        "plt.imshow( sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "pred_prob = F.softmax(model( t_sample ), dim=1)\n",
        "\n",
        "logits = classifier.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "print( 'output for the test samples:\\n', logits )\n",
        "print( 'class prediction for the test samples:\\n', pred_prob.detach() )\n",
        "print( 'predicted as', np.argmax( logits , axis=1) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output for the test samples:\n",
            " [[ 12.063756  -15.246609   -6.698591   -4.172823   -3.0382867  -1.8381689\n",
            "   -4.0149803  -6.4085493  -4.5358186   0.2620315]]\n",
            "class prediction for the test samples:\n",
            " tensor([[9.9999e-01, 1.3780e-12, 7.1058e-09, 8.8826e-08, 2.7622e-07, 9.1721e-07,\n",
            "         1.0401e-07, 9.4968e-09, 6.1786e-08, 7.4916e-06]])\n",
            "predicted as [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73vWZwCnXze7"
      },
      "source": [
        "Since `ART` loads data as numpy array, we create variables as PyTorch Tensor for convenience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:56.753950Z",
          "start_time": "2021-09-20T19:00:56.724948Z"
        },
        "id": "nWIWpQwRXze8"
      },
      "source": [
        "\n",
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "one_hot_y = torch.LongTensor( y_test[ sample_ind, : ].reshape( ( 1, -1 ) ) )\n",
        "t_y = torch.argmax(one_hot_y, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Os0-d5Xze8"
      },
      "source": [
        "Construct adversarial examples from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm1cFKagczmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c20bdd-5d78-417b-ebee-2ece710ab606"
      },
      "source": [
        "print(t_sample.shape,sample.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28]) (1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:58.830194Z",
          "start_time": "2021-09-20T19:00:58.627458Z"
        },
        "id": "F1QyiMFrXze8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "290c1e4b-ad55-49f6-d017-0652cfcb8ed1"
      },
      "source": [
        "# constructing adversarial examples\n",
        "######################\n",
        "# fill in the blanks #\n",
        "######################\n",
        "\n",
        "eps = 0.2 # allowed maximum modification\n",
        "\n",
        "# compute logits\n",
        "logits = model( t_sample )\n",
        "# logits = classifier.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "print(logits)\n",
        "# compute the cross entropy loss of our original sample\n",
        "\n",
        "loss = nn.CrossEntropyLoss()(logits,t_y)\n",
        "\n",
        "# get the gradient wrt to the input. \n",
        "# there are two ways to compute gradients. \n",
        "\n",
        "grads = torch.autograd.grad( loss,[t_sample] )\n",
        "print(grads.shape)\n",
        "\n",
        "# You may see an error `RuntimeError: One of the differentiated Tensors does not require grad`\n",
        "# What does it mean? and how to solve it?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12.0638, -15.2466,  -6.6986,  -4.1728,  -3.0383,  -1.8382,  -4.0150,\n",
            "          -6.4085,  -4.5358,   0.2620]], grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-947c20133524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# there are two ways to compute gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_sample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    226\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xClX2YsOXze9"
      },
      "source": [
        "It's caused by the mechanism of PyTorch.\n",
        "\n",
        "By default, only model's parameters will compute/require gradients.\n",
        "\n",
        "Now, we need to let the input data require gradients. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooA8fm-9ebFE"
      },
      "source": [
        "# x+ϵsign(∇xJ(x,y))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:06.538188Z",
          "start_time": "2021-09-20T19:02:06.405536Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "RovKr9sKIQgh",
        "outputId": "278ee39d-65a1-480d-eae2-bbe418401089"
      },
      "source": [
        "# constructing adversarial examples\n",
        "######################\n",
        "# fill in the blanks #\n",
        "######################\n",
        "\n",
        "eps = 1 # allowed maximum modification and increase it until it's misclassified\n",
        "\n",
        "# Set the data require gradients\n",
        "\n",
        "t_sample.requires_grad = True\n",
        "\n",
        "# compute logits\n",
        "\n",
        "# compute logits\n",
        "logits = model( t_sample )\n",
        "# logits = classifier.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "print(logits)\n",
        "# compute the cross entropy loss of our original sample\n",
        "\n",
        "loss = nn.CrossEntropyLoss()(logits,t_y)\n",
        "\n",
        "# get the gradient wrt to the input. \n",
        "# there are two ways to compute gradients. \n",
        "\n",
        "grads = torch.autograd.grad( loss,[t_sample] )[0]\n",
        "# make sure you get the correct gradients\n",
        "print(grads.shape)\n",
        "\n",
        "# calculate the pertubation\n",
        "\n",
        "perturbation = eps*torch.sign(grads)\n",
        "\n",
        "# apply pertubation, x_adv = x + \\epsilon sign(\\nabla_x J(x, y))\n",
        "\n",
        "x_adv = t_sample + perturbation * eps\n",
        "\n",
        "# now that we have the adversarial examples\n",
        "# get the prediction result and print the adversarial example\n",
        "\n",
        "\n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "\n",
        "print( 'logits for our sample: \\t\\n', logits )\n",
        "pred_prob = F.softmax(model( x_adv ), dim=1)\n",
        "print( 'class prediction for our sample: \\t\\n', pred_prob  )\n",
        "\n",
        "print( 'predicted as', torch.argmax( pred_prob, dim=1)  )\n",
        "# increase eps until it's misclassified\n",
        "\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12.0638, -15.2466,  -6.6986,  -4.1728,  -3.0383,  -1.8382,  -4.0150,\n",
            "          -6.4085,  -4.5358,   0.2620]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([1, 1, 28, 28])\n",
            "our adversarial example\n",
            "torch.Size([1, 1, 28, 28])\n",
            "logits for our sample: \t\n",
            " tensor([[ 12.0638, -15.2466,  -6.6986,  -4.1728,  -3.0383,  -1.8382,  -4.0150,\n",
            "          -6.4085,  -4.5358,   0.2620]], grad_fn=<AddmmBackward>)\n",
            "class prediction for our sample: \t\n",
            " tensor([[3.0866e-08, 5.6155e-19, 5.9528e-09, 1.7974e-08, 1.4107e-06, 4.2591e-11,\n",
            "         5.5666e-12, 3.9524e-06, 5.3996e-06, 9.9999e-01]],\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "predicted as tensor([9])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAIlElEQVR4nO3dMWgU7RrF8ck1RINilCRqlGBAETsRJNrY2ivsFoKFYmFpJYqFlZ2KtQZbwXWxsVAsVBATUtmYQgii4goiSKJFUDFf9V2Qmznv3n3yOmf0/ytzmNnJzhwG9uGd6VteXi4A+PlP1QcAYGWUEzBFOQFTlBMwRTkBU/0qbDab8qfcO3fuyJ03m82et3Wm/q+iiH0vuVX5vdf5/45cy61WS+aNRqNvpb9z5wRMUU7AFOUETFFOwBTlBExRTsAU5QRMyTlndF7nOsuMztuqnGO6fqdFkXf+m/s7r3IGW4Y7J2CKcgKmKCdginICpignYIpyAqYoJ2CqTz19L7WeM8V5JqdUuV4z9zyvruckpebfC+s5gTqhnIApygmYopyAKcoJmKKcgCk5SimKwvYtR45LfBz8rY/ldB5/dYFRClAnlBMwRTkBU5QTMEU5AVOUEzBFOQFTf+ySMec5aOR7Scyliw8fPsh83759Mt+9e3dp1te34jjuv+7evSvzlC1btpRmx48fD+07hSVjALpGOQFTlBMwRTkBU5QTMEU5AVOUEzCVdc7pKjrTqnKG+uPHD5nfu3cv22e3Wq1s+y6Kojh37lxpduDAgayfnVMX1xtzTqBOKCdginICpignYIpyAqYoJ2CKcgKmQs+tjTwrNPesMDLLTB1batb4+fNnmbfb7dLszJkzoc+Ozjkjs8xGoxH6bGVgYEDmnU5H5sPDwzKv+Hm+zDmBOqGcgCnKCZiinIApygmYopyAqX4VRn9ezvnzdM5RScrLly9lfvnyZZlv3bq1NEstjdq+fbvMd+7cKfMrV67IXI1DUmOW3EvKlNQYZ2RkJLT/Kq437pyAKcoJmKKcgCnKCZiinIApygmYopyAKTnnrPIRkjk/O7Xs6tKlSzKfn5+X+c+fP2WuPv/Tp09y2/HxcZnPzMzIfO/evTKvclYZcf78eZkfOXIktP8qlpRx5wRMUU7AFOUETFFOwBTlBExRTsAU5QRMhV4BGJ1FKjnnShcuXJB5ao4ZpdYebt68WW777t07ma9fv17mqe91dna2NHvz5o3c9sWLFzJPPTI0NeNV1qxZI/OrV6/K/NmzZz1/9irg0ZhAnVBOwBTlBExRTsAU5QRMUU7AFOUETIXmnFW6ffu2zOfm5kqzV69eyW0Tr0VMPiM155rIw4cPy1w9E7cbR48eLc0WFxfltps2bZL5t2/fZH727NnSLDUjTZmYmJB56nnBmTHnBOqEcgKmKCdginICpignYIpyAqYoJ2BKzjmLorCdc3Y6HZk/f/68532n5pg5DQ0NyfzQoUMyf/DggcyreP5qt75+/VqanTp1KrTv4eFhmU9OTsr85MmTPX926npqNBrMOYE6oZyAKcoJmKKcgCnKCZiinIAp+QrAnKI/6V+7dk3mVY5DUtauXVuaRUclOeV+JaR6dWL0fKaW8S0sLIT2nwN3TsAU5QRMUU7AFOUETFFOwBTlBExRTsBUZXPO6Mysr2/FVTZdSc28cs/UxsfHS7ODBw+GPjtKnZfUnDJ6Tqenp0PbVyXXqzC5cwKmKCdginICpignYIpyAqYoJ2CKcgKmarueM6foHHTHjh0y379///99TKslNZNzPS/R1yqmztn79+973neu+S93TsAU5QRMUU7AFOUETFFOwBTlBExRTsCUnHO6zry6oeZi0fWaDx8+lHnq2bORtahRkXM6NTUl8/v378u83W7LXD23NmpiYkLmY2NjMs+1ZlPhzgmYopyAKcoJmKKcgCnKCZiinIApygmYqmw9Z52l5pSpvMr58evXr2V+48aN0mxmZkZuu7S0JPPIHDM1m+7v15dyp9OReZWz5zLcOQFTlBMwRTkBU5QTMEU5AVOUEzCVdZQSeZ1clPrpPfroy2PHjsl8cnJS5hFzc3Myv3nzpsy/f/8u8/n5+dIsutQuJbLML/XqxNHR0Z6OqRvRa7msJ9w5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVN9y8vLpWGz2SwPi2oeF/iv2dlZmb99+/Y3Hcn/yjkPjL4KLyL6f0XmyyMjI3Lb1PkeHByUecVWXK/GnRMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwFVrPGVnHlpqRpvZ9/fp1mVc554yIzjGdZ6wDAwMyf/z4cWmWeq3iunXrejqmbqnrMde8nzsnYIpyAqYoJ2CKcgKmKCdginICpignYKqy59ZGbdiwQeYbN24szRYXF1f7cH5R5ZrLlJzHduLECZmnnuf79OnT1TycVRW5lntdx8qdEzBFOQFTlBMwRTkBU5QTMEU5AVNZRyk5X/N3+vRpmd+6das0e/Lkidx2aWmpl0P6LVJLwqKvN2y326VZf7++XFKv4Ut97/gVd07AFOUETFFOwBTlBExRTsAU5QRMUU7AVNZXAOacc0Z8+fJF5tPT0zKfmppazcP5rUZHR2U+NjZWmu3Zs0duGz3f6npK7Tv36ygj/1tqttxoNHgFIFAnlBMwRTkBU5QTMEU5AVOUEzBFOQFToTlnhPOMdGFhQeYfP36U+cWLF2Wu5l7btm2T2+7atUvmKY8ePZL54OBgaZZzjplb9NhzvlqROSdQM5QTMEU5AVOUEzBFOQFTlBMwRTkBU1mfW5tTZGaWmnkNDQ2F8tSxRWZmzusWq5xj/om4cwKmKCdginICpignYIpyAqYoJ2CKcgKm5HrOoihC6zldn1tbZ9FZ4t96TnKux4xiPSdQM5QTMEU5AVOUEzBFOQFTlBMw9ccuGVMjgz95aVP0VXmu39vfOALizgmYopyAKcoJmKKcgCnKCZiinIApygmYknPOVqsV2nlkmU7qs3POvaKzwjpT5yx6PUQ4L/nKhTsnYIpyAqYoJ2CKcgKmKCdginICpignYCr1aEwAFeHOCZiinIApygmYopyAKcoJmKKcgKl/AFpaSu7UiqJ+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azepEwpTewML"
      },
      "source": [
        "The FGSM is one of the most simple attacks.\n",
        "As we can see, results are not very convincing since the perturbation is perceptible.\n",
        "We can improve on it by making it iterative. \n",
        "\n",
        "Using the code from above, create an iterative version of FGSM that calculates a new perturbation for ever iteration and stops once it achieve misclassifaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:19.050472Z",
          "start_time": "2021-09-20T19:02:18.886103Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "mOHo8eQ0gS4F",
        "outputId": "0ed20f0f-9dad-449d-cd88-58b0adc92203"
      },
      "source": [
        "epsilon = 0.005\n",
        "iterations = 10\n",
        "\n",
        "x_adv = t_sample.detach().clone()\n",
        "x_adv.requires_grad = True\n",
        "print(x_adv.shape)\n",
        "for i in range(iterations):\n",
        "    # your code here\n",
        "\n",
        "    # compute logits\n",
        "\n",
        "    logits = model( x_adv )\n",
        "\n",
        "    # compute the loss of our original sample\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(logits,t_y)\n",
        "\n",
        "    # get the gradient wrt to the input.\n",
        "\n",
        "    grads = torch.autograd.grad( loss,[x_adv] )[0]\n",
        "    # print( 'logits for our sample: \\t\\n', logits )\n",
        "    pred_prob = F.softmax(model( x_adv ), dim=1)\n",
        "    # print( 'class prediction for our sample: \\t\\n', pred_prob  )\n",
        "\n",
        "    # print( 'predicted as', torch.argmax( pred_prob, dim=1)  )\n",
        "    # increase eps until it's misclassified\n",
        "    \n",
        "    epsilon+=0.1\n",
        "\n",
        "    # calculate the pertubation\n",
        "    \n",
        "    perturbation = eps*torch.sign(grads)\n",
        "\n",
        "    # apply pertubation\n",
        "\n",
        "    x_adv = t_sample + perturbation * eps\n",
        "    print(torch.argmax( pred_prob, dim=1)[0],t_y)\n",
        "    if torch.argmax( pred_prob, dim=1)[0] != t_y:\n",
        "        print(\"Hi\")\n",
        "        break\n",
        "\n",
        "    \n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "\n",
        "print( 'logits for our sample: \\t\\n', logits )\n",
        "print( 'class prediction for our sample: \\t\\n', pred_prob  )\n",
        "print(\"epsilon \\t\\n\",epsilon-0.1)\n",
        "print( 'predicted as', torch.argmax( pred_prob, dim=1)  )\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "tensor(0) tensor([0])\n",
            "tensor(9) tensor([0])\n",
            "Hi\n",
            "our adversarial example\n",
            "torch.Size([1, 1, 28, 28])\n",
            "logits for our sample: \t\n",
            " tensor([[ 4.9824e+00, -2.1304e+01,  1.4033e-02, -2.5314e+00,  8.4516e-01,\n",
            "         -8.7280e+00, -9.1157e+00, -9.8662e-01,  1.5861e+00,  6.2178e+00]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "class prediction for our sample: \t\n",
            " tensor([[2.2227e-01, 8.5276e-13, 1.5457e-03, 1.2125e-04, 3.5488e-03, 2.4689e-07,\n",
            "         1.6754e-07, 5.6827e-04, 7.4449e-03, 7.6450e-01]],\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "epsilon \t\n",
            " 0.10500000000000001\n",
            "predicted as tensor([9])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VszDZ1p6V7Hc"
      },
      "source": [
        "Let's use `ART` library to do the actual attack.\n",
        "\n",
        "We will also use the FGSM attack to generate an adversarial example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KYm-KCqnLRC"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6SFuY3Iopia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464b3efb-bb02-4b48-cc4d-cf6df82feafe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:36.178871Z",
          "start_time": "2021-09-20T19:02:33.620048Z"
        },
        "id": "NGlgRPsPXze-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b866e51a-5455-472c-d849-0818a608113f"
      },
      "source": [
        "# Evaluate\n",
        "predictions = classifier.predict(x_test)\n",
        "print(np.argmax( predictions , axis=1).shape,y_test.shape)\n",
        " \n",
        "accuracy = accuracy_score(np.argmax(y_test,axis=1),np.argmax( predictions , axis=1))\n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "# your code here\n",
        "attacker = FastGradientMethod(estimator=classifier, eps=1, targeted=True)\n",
        "x_test_adv = attacker.generate(x=x_test, y=np.argmax(y_test,axis=1))\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "predictions =  classifier.predict(x=x_test_adv)\n",
        "accuracy = np.sum(np.argmax(y_test,axis=1)==np.argmax(predictions,axis=1))/len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,) (10000, 10)\n",
            "Accuracy on clean test examples: 97.92999999999999%\n",
            "Accuracy on adversarial test examples: 50.080000000000005%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:39.628928Z",
          "start_time": "2021-09-20T19:02:39.493565Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VXLnboZ9Xze_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "4c96401b-4b9b-479d-9a08-c3be24992917"
      },
      "source": [
        "# Visualize one example\n",
        "x_test_adv = attacker.generate(x=x_test[25:26],y)\n",
        "example_ind=26\n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_test_adv ) )\n",
        "\n",
        "print( 'predicted as' )\n",
        "\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-bad314a5f0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize one example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_test_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexample_ind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'logits for our sample: \\t\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_test_adv\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/attacks/attack.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;31m# Throw error if attack is targeted, but no targets are provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target labels `y` need to be provided for a targeted attack.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Use model predictions as correct outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target labels `y` need to be provided for a targeted attack."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKOomilRXze_"
      },
      "source": [
        "You can see that it's much simpler than we write it from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM_u8f6EXze_"
      },
      "source": [
        "You can check it from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJQIF24Y91W"
      },
      "source": [
        "We have seen that FGSM does not do a great job of producing adversarial examples when work with 0 and 1. Update the code above work on all 10 digits and try for a number of 0 instance what class they get transformed into in an untargeted attack.\n",
        "Alternativley pick a pair of numbers that you think are closer to each orther and the FGSM attack should work better with.\n",
        "\n",
        "\n",
        "`ART` provides more attacks than the once introduced above. Try any other attacks from the official documents.\n",
        "\n",
        "You can find more information on the attacks here: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Attacks, for example, the PGD attack(https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/evasion.html#projected-gradient-descent-pgd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:03:09.706790Z",
          "start_time": "2021-09-20T19:02:44.470933Z"
        },
        "id": "uvZ3hfrNcp9i"
      },
      "source": [
        "# your code here\n",
        "\n",
        "# Evaluate\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = \n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import PGD\n",
        "\n",
        "x_test_adv = \n",
        "\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy =  \n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Visualize one example\n",
        "x_test_adv =  \n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_test_adv ) )\n",
        "\n",
        "print( 'predicted as',  )\n",
        "\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:50:36.653185Z",
          "start_time": "2021-09-20T18:49:54.740Z"
        },
        "id": "qONG9SnSXzfA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}